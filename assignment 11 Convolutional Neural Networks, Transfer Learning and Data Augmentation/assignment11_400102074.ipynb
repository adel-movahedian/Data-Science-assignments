{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3PDil2O9Vdl"
      },
      "source": [
        "\n",
        " # Assignment 11 â€“ Convolutional Neural Networks, Transfer Learning and Data Augmentation\n",
        " **Course:** Data Science  \n",
        " **Topics:** CNN, Hyper-parameter tuning, Data augmentation, Transfer learning  \n",
        " **Student:** Adel Movahedian 400102074\n",
        "\n",
        "\n",
        " -------------------------------------------------------------\n",
        " ## 1. Environment & data\n",
        " I import TensorFlow/Keras and Sci-Kit-Learn utilities, then download\n",
        " the CIFAR-10 data set (50 000 train, 10 000 test, 32Ã—32Ã—3).\n",
        " All pixel values are scaled to [0,1] and the labels one-hot encoded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G_7PYb28FmO",
        "outputId": "f30c009b-c6d3-4f56-d38e-dacedee23258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Train: (50000, 32, 32, 3), Test: (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np, pandas as pd, random, os, math, gc\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "SEED = 2025\n",
        "tf.random.set_seed(SEED);  np.random.seed(SEED);  random.seed(SEED)\n",
        "\n",
        "# Load CIFAR-10\n",
        "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train_full = x_train_full.astype(\"float32\")/255.0\n",
        "x_test        = x_test.astype(\"float32\")/255.0\n",
        "y_train_full  = keras.utils.to_categorical(y_train_full, 10)\n",
        "y_test        = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(f\"Train: {x_train_full.shape}, Test: {x_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L63CAubOBvNu"
      },
      "source": [
        " -------------------------------------------------------------\n",
        " ## 2. 3-fold cross-validation helper\n",
        " The function below accepts a model-building callback so we can reuse it\n",
        " for every hyper-parameter combination and for transfer-learning models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-pfk0MFLB43G"
      },
      "outputs": [],
      "source": [
        "def run_kfold(build_fn, X, y, folds=3, epochs=20, batch_size=64, verbose=0):\n",
        "    kf = KFold(n_splits=folds, shuffle=True, random_state=SEED)\n",
        "    acc_per_fold = []\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"\\nğŸŒ€ Fold {fold+1}/{folds}\")\n",
        "        model = build_fn()\n",
        "        model.compile(optimizer=\"adam\",\n",
        "                      loss=\"categorical_crossentropy\",\n",
        "                      metrics=[\"accuracy\"])\n",
        "        hist = model.fit(X[train_idx], y[train_idx],\n",
        "                         epochs=epochs, batch_size=batch_size,\n",
        "                         validation_data=(X[val_idx], y[val_idx]),\n",
        "                         verbose=verbose)\n",
        "        acc = hist.history[\"val_accuracy\"][-1]\n",
        "        print(f\"Fold {fold+1} val_acc = {acc:.4f}\")\n",
        "        acc_per_fold.append(acc)\n",
        "        # Free memory\n",
        "        keras.backend.clear_session(); gc.collect()\n",
        "    return np.mean(acc_per_fold), acc_per_fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccoOroBIB87B"
      },
      "source": [
        " -------------------------------------------------------------\n",
        " ## 3. Baseline CNN & hyper-parameter grid search\n",
        " We create a tiny CNN with two conv layers, max-pooling, dropout, and a\n",
        " dense softmax head.  \n",
        " **Grid parameters:**  \n",
        " * `kernel_sizes` = [(3,3), (5,5)]  \n",
        " * `conv_strides` = [1, 2, 3]  \n",
        " * `pool_sizes`   = [(3,3), (4,4)]  \n",
        " * `pool_strides` = [2, 3, 4]\n",
        " That yields 3Ã—3Ã—3Ã—3 = 81 configs; to keep Colab runtime reasonable we\n",
        " randomly sample 12 of them (feel free to raise `N_SAMPLE`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivGxQO3lCLQ4",
        "outputId": "4a0263af-d8cf-4782-fb41-39cdad79df9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸŒ€ Fold 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 19ms/step - accuracy: 0.2821 - loss: 1.9478 - val_accuracy: 0.5238 - val_loss: 1.3375\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4853 - loss: 1.4410 - val_accuracy: 0.5747 - val_loss: 1.2019\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5451 - loss: 1.2933 - val_accuracy: 0.6216 - val_loss: 1.0921\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5766 - loss: 1.1922 - val_accuracy: 0.6360 - val_loss: 1.0376\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6011 - loss: 1.1303 - val_accuracy: 0.6505 - val_loss: 1.0126\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.6142 - loss: 1.0853 - val_accuracy: 0.6494 - val_loss: 1.0123\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6319 - loss: 1.0275 - val_accuracy: 0.6674 - val_loss: 0.9534\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6499 - loss: 0.9892 - val_accuracy: 0.6723 - val_loss: 0.9354\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6593 - loss: 0.9541 - val_accuracy: 0.6820 - val_loss: 0.9214\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6688 - loss: 0.9294 - val_accuracy: 0.6806 - val_loss: 0.9214\n",
            "Fold 1 val_acc = 0.6806\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.3041 - loss: 1.8840 - val_accuracy: 0.5084 - val_loss: 1.3786\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4806 - loss: 1.4473 - val_accuracy: 0.5652 - val_loss: 1.2261\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5406 - loss: 1.2906 - val_accuracy: 0.6117 - val_loss: 1.1003\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.5786 - loss: 1.1878 - val_accuracy: 0.6224 - val_loss: 1.0685\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6147 - loss: 1.1032 - val_accuracy: 0.6356 - val_loss: 1.0427\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6256 - loss: 1.0485 - val_accuracy: 0.6581 - val_loss: 0.9797\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6465 - loss: 1.0006 - val_accuracy: 0.6596 - val_loss: 0.9792\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6565 - loss: 0.9611 - val_accuracy: 0.6687 - val_loss: 0.9623\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6712 - loss: 0.9211 - val_accuracy: 0.6755 - val_loss: 0.9435\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6863 - loss: 0.8829 - val_accuracy: 0.6756 - val_loss: 0.9446\n",
            "Fold 2 val_acc = 0.6756\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.2893 - loss: 1.9310 - val_accuracy: 0.5133 - val_loss: 1.3674\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.4710 - loss: 1.4709 - val_accuracy: 0.5548 - val_loss: 1.2551\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5215 - loss: 1.3390 - val_accuracy: 0.5912 - val_loss: 1.1490\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5599 - loss: 1.2328 - val_accuracy: 0.6139 - val_loss: 1.1019\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5770 - loss: 1.1726 - val_accuracy: 0.6380 - val_loss: 1.0316\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5991 - loss: 1.1117 - val_accuracy: 0.6441 - val_loss: 1.0108\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6165 - loss: 1.0829 - val_accuracy: 0.6445 - val_loss: 1.0125\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6276 - loss: 1.0386 - val_accuracy: 0.6532 - val_loss: 0.9901\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6456 - loss: 0.9952 - val_accuracy: 0.6551 - val_loss: 0.9919\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6519 - loss: 0.9745 - val_accuracy: 0.6657 - val_loss: 0.9602\n",
            "Fold 3 val_acc = 0.6657\n",
            "Config {'k': (5, 5), 's': 1, 'p': (3, 3), 'ps': 3} â†’ mean_val_acc = 0.6740\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.2349 - loss: 2.0454 - val_accuracy: 0.4499 - val_loss: 1.5353\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4140 - loss: 1.5913 - val_accuracy: 0.5094 - val_loss: 1.3686\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4640 - loss: 1.4729 - val_accuracy: 0.5244 - val_loss: 1.3157\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4995 - loss: 1.3829 - val_accuracy: 0.5601 - val_loss: 1.2392\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5243 - loss: 1.3271 - val_accuracy: 0.5712 - val_loss: 1.1988\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5392 - loss: 1.2762 - val_accuracy: 0.5813 - val_loss: 1.1629\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5534 - loss: 1.2382 - val_accuracy: 0.5936 - val_loss: 1.1461\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5714 - loss: 1.2043 - val_accuracy: 0.6012 - val_loss: 1.1290\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5811 - loss: 1.1713 - val_accuracy: 0.5976 - val_loss: 1.1568\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5834 - loss: 1.1618 - val_accuracy: 0.6021 - val_loss: 1.1330\n",
            "Fold 1 val_acc = 0.6021\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.2402 - loss: 2.0293 - val_accuracy: 0.4240 - val_loss: 1.5661\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4220 - loss: 1.5782 - val_accuracy: 0.5013 - val_loss: 1.3641\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4777 - loss: 1.4370 - val_accuracy: 0.5385 - val_loss: 1.2723\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5103 - loss: 1.3537 - val_accuracy: 0.5520 - val_loss: 1.2216\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5318 - loss: 1.2934 - val_accuracy: 0.5727 - val_loss: 1.1812\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5546 - loss: 1.2378 - val_accuracy: 0.5681 - val_loss: 1.1905\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5667 - loss: 1.2064 - val_accuracy: 0.5902 - val_loss: 1.1441\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5876 - loss: 1.1524 - val_accuracy: 0.5920 - val_loss: 1.1489\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5911 - loss: 1.1427 - val_accuracy: 0.6045 - val_loss: 1.1112\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5959 - loss: 1.1214 - val_accuracy: 0.5988 - val_loss: 1.1247\n",
            "Fold 2 val_acc = 0.5988\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.2262 - loss: 2.0506 - val_accuracy: 0.4407 - val_loss: 1.5381\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4139 - loss: 1.5865 - val_accuracy: 0.4979 - val_loss: 1.3945\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4729 - loss: 1.4551 - val_accuracy: 0.5429 - val_loss: 1.2900\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5032 - loss: 1.3796 - val_accuracy: 0.5612 - val_loss: 1.2249\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5273 - loss: 1.3167 - val_accuracy: 0.5595 - val_loss: 1.2315\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5411 - loss: 1.2792 - val_accuracy: 0.5836 - val_loss: 1.1672\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5562 - loss: 1.2325 - val_accuracy: 0.5806 - val_loss: 1.1678\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5735 - loss: 1.1958 - val_accuracy: 0.5898 - val_loss: 1.1431\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5784 - loss: 1.1692 - val_accuracy: 0.5967 - val_loss: 1.1300\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5931 - loss: 1.1447 - val_accuracy: 0.6087 - val_loss: 1.1015\n",
            "Fold 3 val_acc = 0.6087\n",
            "Config {'k': (5, 5), 's': 2, 'p': (4, 4), 'ps': 2} â†’ mean_val_acc = 0.6032\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.1819 - loss: 2.1576 - val_accuracy: 0.3763 - val_loss: 1.7167\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3429 - loss: 1.7700 - val_accuracy: 0.4222 - val_loss: 1.5807\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3862 - loss: 1.6640 - val_accuracy: 0.4567 - val_loss: 1.5080\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4119 - loss: 1.5983 - val_accuracy: 0.4632 - val_loss: 1.4743\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4321 - loss: 1.5468 - val_accuracy: 0.4753 - val_loss: 1.4473\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4452 - loss: 1.5115 - val_accuracy: 0.4846 - val_loss: 1.4306\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4580 - loss: 1.4823 - val_accuracy: 0.4943 - val_loss: 1.4102\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4683 - loss: 1.4507 - val_accuracy: 0.4992 - val_loss: 1.3756\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4762 - loss: 1.4249 - val_accuracy: 0.5067 - val_loss: 1.3662\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4818 - loss: 1.4162 - val_accuracy: 0.5045 - val_loss: 1.3594\n",
            "Fold 1 val_acc = 0.5045\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.1876 - loss: 2.1480 - val_accuracy: 0.3442 - val_loss: 1.7742\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3400 - loss: 1.7872 - val_accuracy: 0.4280 - val_loss: 1.5818\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3906 - loss: 1.6626 - val_accuracy: 0.4571 - val_loss: 1.4886\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4188 - loss: 1.5958 - val_accuracy: 0.4721 - val_loss: 1.4607\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4284 - loss: 1.5521 - val_accuracy: 0.4765 - val_loss: 1.4392\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4438 - loss: 1.5201 - val_accuracy: 0.4877 - val_loss: 1.4042\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4601 - loss: 1.4813 - val_accuracy: 0.4903 - val_loss: 1.3827\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4662 - loss: 1.4642 - val_accuracy: 0.4933 - val_loss: 1.3810\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4789 - loss: 1.4347 - val_accuracy: 0.5045 - val_loss: 1.3491\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4846 - loss: 1.4079 - val_accuracy: 0.5067 - val_loss: 1.3536\n",
            "Fold 2 val_acc = 0.5067\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.1868 - loss: 2.1457 - val_accuracy: 0.3701 - val_loss: 1.7280\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3338 - loss: 1.7810 - val_accuracy: 0.4146 - val_loss: 1.6107\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3812 - loss: 1.6747 - val_accuracy: 0.4440 - val_loss: 1.5287\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4067 - loss: 1.6095 - val_accuracy: 0.4602 - val_loss: 1.4754\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4222 - loss: 1.5604 - val_accuracy: 0.4661 - val_loss: 1.4651\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4353 - loss: 1.5216 - val_accuracy: 0.4839 - val_loss: 1.4186\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4542 - loss: 1.4887 - val_accuracy: 0.4907 - val_loss: 1.3985\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4624 - loss: 1.4631 - val_accuracy: 0.5002 - val_loss: 1.3857\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4696 - loss: 1.4445 - val_accuracy: 0.4935 - val_loss: 1.3915\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4806 - loss: 1.4176 - val_accuracy: 0.5032 - val_loss: 1.3680\n",
            "Fold 3 val_acc = 0.5032\n",
            "Config {'k': (5, 5), 's': 3, 'p': (4, 4), 'ps': 3} â†’ mean_val_acc = 0.5048\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.2289 - loss: 2.0496 - val_accuracy: 0.4621 - val_loss: 1.4982\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4080 - loss: 1.6059 - val_accuracy: 0.5066 - val_loss: 1.3803\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4598 - loss: 1.4784 - val_accuracy: 0.5417 - val_loss: 1.2925\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4901 - loss: 1.4080 - val_accuracy: 0.5496 - val_loss: 1.2601\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5077 - loss: 1.3627 - val_accuracy: 0.5676 - val_loss: 1.2132\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5249 - loss: 1.3128 - val_accuracy: 0.5813 - val_loss: 1.1798\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5392 - loss: 1.2872 - val_accuracy: 0.5933 - val_loss: 1.1476\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5483 - loss: 1.2539 - val_accuracy: 0.5961 - val_loss: 1.1405\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5621 - loss: 1.2310 - val_accuracy: 0.6055 - val_loss: 1.1161\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5673 - loss: 1.2057 - val_accuracy: 0.6040 - val_loss: 1.1144\n",
            "Fold 1 val_acc = 0.6040\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2223 - loss: 2.0594 - val_accuracy: 0.4279 - val_loss: 1.5906\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3984 - loss: 1.6310 - val_accuracy: 0.4944 - val_loss: 1.4129\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4531 - loss: 1.4994 - val_accuracy: 0.5268 - val_loss: 1.3341\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4890 - loss: 1.4121 - val_accuracy: 0.5496 - val_loss: 1.2663\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5082 - loss: 1.3643 - val_accuracy: 0.5678 - val_loss: 1.2209\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5235 - loss: 1.3182 - val_accuracy: 0.5781 - val_loss: 1.1967\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5418 - loss: 1.2706 - val_accuracy: 0.5816 - val_loss: 1.1827\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5520 - loss: 1.2451 - val_accuracy: 0.5885 - val_loss: 1.1567\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5583 - loss: 1.2338 - val_accuracy: 0.5928 - val_loss: 1.1399\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5698 - loss: 1.2071 - val_accuracy: 0.5981 - val_loss: 1.1303\n",
            "Fold 2 val_acc = 0.5981\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.2283 - loss: 2.0474 - val_accuracy: 0.4365 - val_loss: 1.5520\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3995 - loss: 1.6227 - val_accuracy: 0.4888 - val_loss: 1.4090\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4503 - loss: 1.5047 - val_accuracy: 0.5140 - val_loss: 1.3354\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4806 - loss: 1.4260 - val_accuracy: 0.5332 - val_loss: 1.2811\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4998 - loss: 1.3749 - val_accuracy: 0.5539 - val_loss: 1.2364\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5185 - loss: 1.3223 - val_accuracy: 0.5698 - val_loss: 1.1939\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5404 - loss: 1.2833 - val_accuracy: 0.5794 - val_loss: 1.1762\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5509 - loss: 1.2593 - val_accuracy: 0.5852 - val_loss: 1.1539\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5567 - loss: 1.2286 - val_accuracy: 0.6018 - val_loss: 1.1225\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5687 - loss: 1.2045 - val_accuracy: 0.6010 - val_loss: 1.1157\n",
            "Fold 3 val_acc = 0.6010\n",
            "Config {'k': (3, 3), 's': 2, 'p': (4, 4), 'ps': 2} â†’ mean_val_acc = 0.6011\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.3007 - loss: 1.8952 - val_accuracy: 0.5630 - val_loss: 1.2891\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5055 - loss: 1.3670 - val_accuracy: 0.6207 - val_loss: 1.0940\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5649 - loss: 1.2243 - val_accuracy: 0.6398 - val_loss: 1.0356\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5996 - loss: 1.1331 - val_accuracy: 0.6587 - val_loss: 0.9836\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6233 - loss: 1.0702 - val_accuracy: 0.6666 - val_loss: 0.9675\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6436 - loss: 1.0157 - val_accuracy: 0.6733 - val_loss: 0.9356\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6552 - loss: 0.9796 - val_accuracy: 0.6858 - val_loss: 0.9018\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6723 - loss: 0.9294 - val_accuracy: 0.6939 - val_loss: 0.8796\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6810 - loss: 0.8998 - val_accuracy: 0.6922 - val_loss: 0.8815\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6923 - loss: 0.8736 - val_accuracy: 0.6980 - val_loss: 0.8660\n",
            "Fold 1 val_acc = 0.6980\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3162 - loss: 1.8714 - val_accuracy: 0.5525 - val_loss: 1.2828\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5204 - loss: 1.3375 - val_accuracy: 0.6170 - val_loss: 1.0858\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5832 - loss: 1.1743 - val_accuracy: 0.6357 - val_loss: 1.0405\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6194 - loss: 1.0886 - val_accuracy: 0.6588 - val_loss: 0.9779\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6377 - loss: 1.0271 - val_accuracy: 0.6659 - val_loss: 0.9460\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6538 - loss: 0.9778 - val_accuracy: 0.6807 - val_loss: 0.9090\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6660 - loss: 0.9288 - val_accuracy: 0.6846 - val_loss: 0.8905\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6809 - loss: 0.9005 - val_accuracy: 0.6905 - val_loss: 0.8782\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6916 - loss: 0.8651 - val_accuracy: 0.6803 - val_loss: 0.9061\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6998 - loss: 0.8391 - val_accuracy: 0.6905 - val_loss: 0.8778\n",
            "Fold 2 val_acc = 0.6905\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.3067 - loss: 1.8681 - val_accuracy: 0.5518 - val_loss: 1.2677\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.5220 - loss: 1.3376 - val_accuracy: 0.6174 - val_loss: 1.1047\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5769 - loss: 1.1956 - val_accuracy: 0.6319 - val_loss: 1.0467\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6119 - loss: 1.1037 - val_accuracy: 0.6600 - val_loss: 0.9708\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6290 - loss: 1.0505 - val_accuracy: 0.6704 - val_loss: 0.9482\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6492 - loss: 0.9857 - val_accuracy: 0.6754 - val_loss: 0.9263\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6583 - loss: 0.9575 - val_accuracy: 0.6702 - val_loss: 0.9435\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6725 - loss: 0.9227 - val_accuracy: 0.6968 - val_loss: 0.8713\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6785 - loss: 0.8936 - val_accuracy: 0.6868 - val_loss: 0.8954\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6888 - loss: 0.8635 - val_accuracy: 0.6954 - val_loss: 0.8778\n",
            "Fold 3 val_acc = 0.6954\n",
            "Config {'k': (3, 3), 's': 1, 'p': (4, 4), 'ps': 3} â†’ mean_val_acc = 0.6946\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.2045 - loss: 2.1087 - val_accuracy: 0.4249 - val_loss: 1.6060\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3904 - loss: 1.6599 - val_accuracy: 0.4733 - val_loss: 1.4555\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4379 - loss: 1.5371 - val_accuracy: 0.5109 - val_loss: 1.3675\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4676 - loss: 1.4608 - val_accuracy: 0.5378 - val_loss: 1.2966\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4917 - loss: 1.3964 - val_accuracy: 0.5589 - val_loss: 1.2457\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5132 - loss: 1.3527 - val_accuracy: 0.5606 - val_loss: 1.2203\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5259 - loss: 1.3062 - val_accuracy: 0.5754 - val_loss: 1.1921\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5463 - loss: 1.2693 - val_accuracy: 0.5827 - val_loss: 1.1689\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5455 - loss: 1.2535 - val_accuracy: 0.5900 - val_loss: 1.1604\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5519 - loss: 1.2314 - val_accuracy: 0.5909 - val_loss: 1.1590\n",
            "Fold 1 val_acc = 0.5909\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2347 - loss: 2.0345 - val_accuracy: 0.4238 - val_loss: 1.5730\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4077 - loss: 1.6118 - val_accuracy: 0.4882 - val_loss: 1.4053\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4607 - loss: 1.4793 - val_accuracy: 0.5147 - val_loss: 1.3260\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4928 - loss: 1.4025 - val_accuracy: 0.5393 - val_loss: 1.2670\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5178 - loss: 1.3395 - val_accuracy: 0.5635 - val_loss: 1.2119\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5315 - loss: 1.2936 - val_accuracy: 0.5708 - val_loss: 1.1851\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5472 - loss: 1.2535 - val_accuracy: 0.5795 - val_loss: 1.1631\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5548 - loss: 1.2319 - val_accuracy: 0.5861 - val_loss: 1.1472\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5737 - loss: 1.1962 - val_accuracy: 0.5881 - val_loss: 1.1424\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5820 - loss: 1.1710 - val_accuracy: 0.6035 - val_loss: 1.1050\n",
            "Fold 2 val_acc = 0.6035\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.2196 - loss: 2.0762 - val_accuracy: 0.4127 - val_loss: 1.6259\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3916 - loss: 1.6428 - val_accuracy: 0.4647 - val_loss: 1.4962\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4457 - loss: 1.5160 - val_accuracy: 0.5104 - val_loss: 1.3670\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4746 - loss: 1.4386 - val_accuracy: 0.5301 - val_loss: 1.3170\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4950 - loss: 1.3900 - val_accuracy: 0.5413 - val_loss: 1.2716\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5102 - loss: 1.3386 - val_accuracy: 0.5552 - val_loss: 1.2583\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5262 - loss: 1.3143 - val_accuracy: 0.5640 - val_loss: 1.2345\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5303 - loss: 1.2936 - val_accuracy: 0.5703 - val_loss: 1.2178\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5437 - loss: 1.2670 - val_accuracy: 0.5845 - val_loss: 1.1874\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5507 - loss: 1.2425 - val_accuracy: 0.5872 - val_loss: 1.1587\n",
            "Fold 3 val_acc = 0.5872\n",
            "Config {'k': (5, 5), 's': 2, 'p': (3, 3), 'ps': 4} â†’ mean_val_acc = 0.5939\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.1831 - loss: 2.1605 - val_accuracy: 0.3451 - val_loss: 1.8104\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3094 - loss: 1.8614 - val_accuracy: 0.3910 - val_loss: 1.6781\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3495 - loss: 1.7598 - val_accuracy: 0.4103 - val_loss: 1.6233\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3682 - loss: 1.7064 - val_accuracy: 0.4298 - val_loss: 1.5715\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3866 - loss: 1.6600 - val_accuracy: 0.4389 - val_loss: 1.5476\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3948 - loss: 1.6388 - val_accuracy: 0.4424 - val_loss: 1.5305\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3990 - loss: 1.6111 - val_accuracy: 0.4494 - val_loss: 1.5177\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4160 - loss: 1.5937 - val_accuracy: 0.4566 - val_loss: 1.4963\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4188 - loss: 1.5753 - val_accuracy: 0.4600 - val_loss: 1.4906\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4296 - loss: 1.5610 - val_accuracy: 0.4687 - val_loss: 1.4682\n",
            "Fold 1 val_acc = 0.4687\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.1793 - loss: 2.1697 - val_accuracy: 0.3284 - val_loss: 1.8494\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3105 - loss: 1.8685 - val_accuracy: 0.3886 - val_loss: 1.7006\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3427 - loss: 1.7781 - val_accuracy: 0.4012 - val_loss: 1.6394\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3608 - loss: 1.7229 - val_accuracy: 0.4138 - val_loss: 1.5998\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3791 - loss: 1.6833 - val_accuracy: 0.4236 - val_loss: 1.5701\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3922 - loss: 1.6547 - val_accuracy: 0.4329 - val_loss: 1.5543\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3953 - loss: 1.6352 - val_accuracy: 0.4366 - val_loss: 1.5363\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4023 - loss: 1.6178 - val_accuracy: 0.4464 - val_loss: 1.5186\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4072 - loss: 1.6035 - val_accuracy: 0.4485 - val_loss: 1.5116\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4153 - loss: 1.5854 - val_accuracy: 0.4527 - val_loss: 1.5006\n",
            "Fold 2 val_acc = 0.4527\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.1716 - loss: 2.1883 - val_accuracy: 0.3297 - val_loss: 1.8573\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3066 - loss: 1.8757 - val_accuracy: 0.3856 - val_loss: 1.7033\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3509 - loss: 1.7680 - val_accuracy: 0.4065 - val_loss: 1.6320\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3702 - loss: 1.7163 - val_accuracy: 0.4174 - val_loss: 1.5948\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3791 - loss: 1.6869 - val_accuracy: 0.4240 - val_loss: 1.5810\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3898 - loss: 1.6582 - val_accuracy: 0.4427 - val_loss: 1.5423\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4003 - loss: 1.6300 - val_accuracy: 0.4454 - val_loss: 1.5371\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4098 - loss: 1.6092 - val_accuracy: 0.4512 - val_loss: 1.5130\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4166 - loss: 1.5918 - val_accuracy: 0.4533 - val_loss: 1.5083\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4207 - loss: 1.5762 - val_accuracy: 0.4524 - val_loss: 1.5100\n",
            "Fold 3 val_acc = 0.4524\n",
            "Config {'k': (3, 3), 's': 3, 'p': (4, 4), 'ps': 4} â†’ mean_val_acc = 0.4579\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.2782 - loss: 1.9403 - val_accuracy: 0.5093 - val_loss: 1.3934\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4744 - loss: 1.4627 - val_accuracy: 0.5753 - val_loss: 1.2073\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5404 - loss: 1.3081 - val_accuracy: 0.6148 - val_loss: 1.1069\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5690 - loss: 1.2131 - val_accuracy: 0.6393 - val_loss: 1.0388\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5977 - loss: 1.1303 - val_accuracy: 0.6488 - val_loss: 0.9976\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6147 - loss: 1.0926 - val_accuracy: 0.6621 - val_loss: 0.9760\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.6324 - loss: 1.0342 - val_accuracy: 0.6670 - val_loss: 0.9662\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6428 - loss: 0.9974 - val_accuracy: 0.6662 - val_loss: 0.9615\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.6562 - loss: 0.9653 - val_accuracy: 0.6713 - val_loss: 0.9389\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6710 - loss: 0.9336 - val_accuracy: 0.6782 - val_loss: 0.9347\n",
            "Fold 1 val_acc = 0.6782\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.3022 - loss: 1.8884 - val_accuracy: 0.5113 - val_loss: 1.3725\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4925 - loss: 1.4207 - val_accuracy: 0.5763 - val_loss: 1.2010\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5430 - loss: 1.2797 - val_accuracy: 0.6069 - val_loss: 1.1155\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5787 - loss: 1.1795 - val_accuracy: 0.6315 - val_loss: 1.0401\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6040 - loss: 1.1134 - val_accuracy: 0.6264 - val_loss: 1.0626\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6248 - loss: 1.0551 - val_accuracy: 0.6435 - val_loss: 0.9950\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6421 - loss: 1.0098 - val_accuracy: 0.6499 - val_loss: 0.9913\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6556 - loss: 0.9651 - val_accuracy: 0.6621 - val_loss: 0.9604\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6621 - loss: 0.9477 - val_accuracy: 0.6695 - val_loss: 0.9473\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6778 - loss: 0.9037 - val_accuracy: 0.6672 - val_loss: 0.9539\n",
            "Fold 2 val_acc = 0.6672\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.3013 - loss: 1.8803 - val_accuracy: 0.5148 - val_loss: 1.3463\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.4910 - loss: 1.4057 - val_accuracy: 0.5770 - val_loss: 1.2097\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5492 - loss: 1.2728 - val_accuracy: 0.6268 - val_loss: 1.0657\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5859 - loss: 1.1765 - val_accuracy: 0.6376 - val_loss: 1.0270\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6068 - loss: 1.1028 - val_accuracy: 0.6503 - val_loss: 1.0126\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6301 - loss: 1.0466 - val_accuracy: 0.6594 - val_loss: 0.9819\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6386 - loss: 1.0117 - val_accuracy: 0.6684 - val_loss: 0.9546\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6604 - loss: 0.9685 - val_accuracy: 0.6678 - val_loss: 0.9679\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6679 - loss: 0.9348 - val_accuracy: 0.6698 - val_loss: 0.9631\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6809 - loss: 0.8904 - val_accuracy: 0.6783 - val_loss: 0.9331\n",
            "Fold 3 val_acc = 0.6783\n",
            "Config {'k': (5, 5), 's': 1, 'p': (3, 3), 'ps': 4} â†’ mean_val_acc = 0.6746\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2056 - loss: 2.1003 - val_accuracy: 0.3949 - val_loss: 1.6610\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3542 - loss: 1.7181 - val_accuracy: 0.4514 - val_loss: 1.5184\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4142 - loss: 1.5906 - val_accuracy: 0.4912 - val_loss: 1.4116\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4504 - loss: 1.5060 - val_accuracy: 0.5141 - val_loss: 1.3601\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4728 - loss: 1.4493 - val_accuracy: 0.5227 - val_loss: 1.3185\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4909 - loss: 1.4124 - val_accuracy: 0.5511 - val_loss: 1.2770\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4964 - loss: 1.3784 - val_accuracy: 0.5553 - val_loss: 1.2622\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5101 - loss: 1.3510 - val_accuracy: 0.5615 - val_loss: 1.2375\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5222 - loss: 1.3252 - val_accuracy: 0.5623 - val_loss: 1.2401\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5262 - loss: 1.3063 - val_accuracy: 0.5715 - val_loss: 1.1926\n",
            "Fold 1 val_acc = 0.5715\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2111 - loss: 2.0923 - val_accuracy: 0.3997 - val_loss: 1.6601\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3644 - loss: 1.7057 - val_accuracy: 0.4424 - val_loss: 1.5320\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4111 - loss: 1.5890 - val_accuracy: 0.4906 - val_loss: 1.4287\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4472 - loss: 1.5077 - val_accuracy: 0.5134 - val_loss: 1.3688\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4684 - loss: 1.4556 - val_accuracy: 0.5282 - val_loss: 1.3189\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4888 - loss: 1.4128 - val_accuracy: 0.5454 - val_loss: 1.2773\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5037 - loss: 1.3759 - val_accuracy: 0.5534 - val_loss: 1.2536\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5128 - loss: 1.3503 - val_accuracy: 0.5574 - val_loss: 1.2313\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5223 - loss: 1.3293 - val_accuracy: 0.5649 - val_loss: 1.2122\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5340 - loss: 1.3001 - val_accuracy: 0.5699 - val_loss: 1.1995\n",
            "Fold 2 val_acc = 0.5699\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2049 - loss: 2.0990 - val_accuracy: 0.3953 - val_loss: 1.6571\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3587 - loss: 1.7237 - val_accuracy: 0.4483 - val_loss: 1.5186\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4136 - loss: 1.5980 - val_accuracy: 0.4892 - val_loss: 1.4326\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4451 - loss: 1.5279 - val_accuracy: 0.4990 - val_loss: 1.3870\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4618 - loss: 1.4774 - val_accuracy: 0.5257 - val_loss: 1.3288\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4807 - loss: 1.4352 - val_accuracy: 0.5389 - val_loss: 1.2969\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4917 - loss: 1.4014 - val_accuracy: 0.5453 - val_loss: 1.2705\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5005 - loss: 1.3802 - val_accuracy: 0.5477 - val_loss: 1.2583\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5155 - loss: 1.3442 - val_accuracy: 0.5587 - val_loss: 1.2370\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5205 - loss: 1.3232 - val_accuracy: 0.5619 - val_loss: 1.2281\n",
            "Fold 3 val_acc = 0.5619\n",
            "Config {'k': (3, 3), 's': 2, 'p': (4, 4), 'ps': 3} â†’ mean_val_acc = 0.5678\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1730 - loss: 2.1813 - val_accuracy: 0.3653 - val_loss: 1.8055\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3094 - loss: 1.8585 - val_accuracy: 0.3972 - val_loss: 1.6784\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3502 - loss: 1.7666 - val_accuracy: 0.4105 - val_loss: 1.6239\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3711 - loss: 1.7142 - val_accuracy: 0.4220 - val_loss: 1.5903\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3813 - loss: 1.6763 - val_accuracy: 0.4339 - val_loss: 1.5620\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3959 - loss: 1.6465 - val_accuracy: 0.4349 - val_loss: 1.5448\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3965 - loss: 1.6283 - val_accuracy: 0.4486 - val_loss: 1.5220\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4056 - loss: 1.6038 - val_accuracy: 0.4468 - val_loss: 1.5139\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4136 - loss: 1.5965 - val_accuracy: 0.4530 - val_loss: 1.5062\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4220 - loss: 1.5744 - val_accuracy: 0.4634 - val_loss: 1.4810\n",
            "Fold 1 val_acc = 0.4634\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.1690 - loss: 2.1836 - val_accuracy: 0.3307 - val_loss: 1.8302\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3031 - loss: 1.8685 - val_accuracy: 0.3914 - val_loss: 1.6874\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3550 - loss: 1.7576 - val_accuracy: 0.4156 - val_loss: 1.6152\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3732 - loss: 1.7030 - val_accuracy: 0.4221 - val_loss: 1.5916\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3893 - loss: 1.6702 - val_accuracy: 0.4284 - val_loss: 1.5626\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3975 - loss: 1.6411 - val_accuracy: 0.4360 - val_loss: 1.5314\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4084 - loss: 1.6127 - val_accuracy: 0.4409 - val_loss: 1.5236\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4140 - loss: 1.6008 - val_accuracy: 0.4486 - val_loss: 1.5049\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4176 - loss: 1.5821 - val_accuracy: 0.4612 - val_loss: 1.4822\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4238 - loss: 1.5697 - val_accuracy: 0.4621 - val_loss: 1.4831\n",
            "Fold 2 val_acc = 0.4621\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.1738 - loss: 2.1740 - val_accuracy: 0.3245 - val_loss: 1.8565\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3011 - loss: 1.8735 - val_accuracy: 0.3777 - val_loss: 1.7148\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3409 - loss: 1.7781 - val_accuracy: 0.4033 - val_loss: 1.6295\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3691 - loss: 1.7220 - val_accuracy: 0.4178 - val_loss: 1.5863\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3846 - loss: 1.6728 - val_accuracy: 0.4370 - val_loss: 1.5424\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3974 - loss: 1.6455 - val_accuracy: 0.4457 - val_loss: 1.5284\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4059 - loss: 1.6171 - val_accuracy: 0.4478 - val_loss: 1.5087\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4042 - loss: 1.6027 - val_accuracy: 0.4541 - val_loss: 1.4970\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4147 - loss: 1.5844 - val_accuracy: 0.4627 - val_loss: 1.4810\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4222 - loss: 1.5635 - val_accuracy: 0.4597 - val_loss: 1.4795\n",
            "Fold 3 val_acc = 0.4597\n",
            "Config {'k': (3, 3), 's': 3, 'p': (4, 4), 'ps': 2} â†’ mean_val_acc = 0.4618\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.1981 - loss: 2.1298 - val_accuracy: 0.3878 - val_loss: 1.7056\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3554 - loss: 1.7458 - val_accuracy: 0.4390 - val_loss: 1.5569\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3990 - loss: 1.6391 - val_accuracy: 0.4612 - val_loss: 1.4781\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4256 - loss: 1.5691 - val_accuracy: 0.4735 - val_loss: 1.4415\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4423 - loss: 1.5263 - val_accuracy: 0.4891 - val_loss: 1.4070\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4554 - loss: 1.4894 - val_accuracy: 0.4913 - val_loss: 1.3990\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4597 - loss: 1.4615 - val_accuracy: 0.4987 - val_loss: 1.3703\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4760 - loss: 1.4336 - val_accuracy: 0.5065 - val_loss: 1.3574\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4904 - loss: 1.3983 - val_accuracy: 0.5073 - val_loss: 1.3531\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4959 - loss: 1.3796 - val_accuracy: 0.5241 - val_loss: 1.3182\n",
            "Fold 1 val_acc = 0.5241\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.1892 - loss: 2.1394 - val_accuracy: 0.3614 - val_loss: 1.7407\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3471 - loss: 1.7717 - val_accuracy: 0.4329 - val_loss: 1.5720\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3868 - loss: 1.6629 - val_accuracy: 0.4555 - val_loss: 1.4980\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4185 - loss: 1.5955 - val_accuracy: 0.4656 - val_loss: 1.4691\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4376 - loss: 1.5422 - val_accuracy: 0.4892 - val_loss: 1.4098\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4508 - loss: 1.4981 - val_accuracy: 0.4900 - val_loss: 1.4094\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4596 - loss: 1.4737 - val_accuracy: 0.4932 - val_loss: 1.3847\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4684 - loss: 1.4464 - val_accuracy: 0.5061 - val_loss: 1.3617\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4767 - loss: 1.4224 - val_accuracy: 0.5125 - val_loss: 1.3474\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4905 - loss: 1.4069 - val_accuracy: 0.5129 - val_loss: 1.3326\n",
            "Fold 2 val_acc = 0.5129\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.2029 - loss: 2.1159 - val_accuracy: 0.3949 - val_loss: 1.6603\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3583 - loss: 1.7248 - val_accuracy: 0.4401 - val_loss: 1.5484\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4075 - loss: 1.6099 - val_accuracy: 0.4742 - val_loss: 1.4439\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4346 - loss: 1.5303 - val_accuracy: 0.4945 - val_loss: 1.3863\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4613 - loss: 1.4762 - val_accuracy: 0.5084 - val_loss: 1.3537\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4710 - loss: 1.4435 - val_accuracy: 0.5070 - val_loss: 1.3480\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4846 - loss: 1.4110 - val_accuracy: 0.5230 - val_loss: 1.3195\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5026 - loss: 1.3725 - val_accuracy: 0.5297 - val_loss: 1.2944\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5057 - loss: 1.3459 - val_accuracy: 0.5310 - val_loss: 1.2930\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5172 - loss: 1.3188 - val_accuracy: 0.5339 - val_loss: 1.2782\n",
            "Fold 3 val_acc = 0.5339\n",
            "Config {'k': (5, 5), 's': 3, 'p': (4, 4), 'ps': 2} â†’ mean_val_acc = 0.5236\n",
            "\n",
            "ğŸŒ€ Fold 1/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2131 - loss: 2.0703 - val_accuracy: 0.4359 - val_loss: 1.5686\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3985 - loss: 1.6369 - val_accuracy: 0.4957 - val_loss: 1.4005\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4549 - loss: 1.4989 - val_accuracy: 0.5303 - val_loss: 1.3179\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4869 - loss: 1.4117 - val_accuracy: 0.5506 - val_loss: 1.2655\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5100 - loss: 1.3495 - val_accuracy: 0.5644 - val_loss: 1.2243\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5303 - loss: 1.3042 - val_accuracy: 0.5727 - val_loss: 1.2003\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5425 - loss: 1.2689 - val_accuracy: 0.5807 - val_loss: 1.1717\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5538 - loss: 1.2349 - val_accuracy: 0.5780 - val_loss: 1.1849\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5634 - loss: 1.2115 - val_accuracy: 0.5877 - val_loss: 1.1644\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5770 - loss: 1.1788 - val_accuracy: 0.5882 - val_loss: 1.1610\n",
            "Fold 1 val_acc = 0.5882\n",
            "\n",
            "ğŸŒ€ Fold 2/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.2107 - loss: 2.0862 - val_accuracy: 0.3988 - val_loss: 1.6605\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3944 - loss: 1.6410 - val_accuracy: 0.4742 - val_loss: 1.4431\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4584 - loss: 1.4880 - val_accuracy: 0.5136 - val_loss: 1.3360\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4920 - loss: 1.4005 - val_accuracy: 0.5487 - val_loss: 1.2486\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5150 - loss: 1.3366 - val_accuracy: 0.5605 - val_loss: 1.2264\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5363 - loss: 1.2936 - val_accuracy: 0.5813 - val_loss: 1.1759\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5526 - loss: 1.2381 - val_accuracy: 0.5856 - val_loss: 1.1645\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5722 - loss: 1.2002 - val_accuracy: 0.5965 - val_loss: 1.1361\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5769 - loss: 1.1761 - val_accuracy: 0.5932 - val_loss: 1.1379\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5916 - loss: 1.1427 - val_accuracy: 0.5993 - val_loss: 1.1137\n",
            "Fold 2 val_acc = 0.5993\n",
            "\n",
            "ğŸŒ€ Fold 3/3\n",
            "Epoch 1/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2125 - loss: 2.0870 - val_accuracy: 0.4228 - val_loss: 1.5910\n",
            "Epoch 2/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3921 - loss: 1.6395 - val_accuracy: 0.4710 - val_loss: 1.4581\n",
            "Epoch 3/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4451 - loss: 1.5198 - val_accuracy: 0.5077 - val_loss: 1.3605\n",
            "Epoch 4/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4759 - loss: 1.4332 - val_accuracy: 0.5427 - val_loss: 1.2986\n",
            "Epoch 5/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4968 - loss: 1.3722 - val_accuracy: 0.5528 - val_loss: 1.2488\n",
            "Epoch 6/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5194 - loss: 1.3268 - val_accuracy: 0.5585 - val_loss: 1.2255\n",
            "Epoch 7/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5329 - loss: 1.2950 - val_accuracy: 0.5737 - val_loss: 1.1821\n",
            "Epoch 8/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5435 - loss: 1.2588 - val_accuracy: 0.5766 - val_loss: 1.1786\n",
            "Epoch 9/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5580 - loss: 1.2229 - val_accuracy: 0.5911 - val_loss: 1.1418\n",
            "Epoch 10/10\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5617 - loss: 1.2115 - val_accuracy: 0.5899 - val_loss: 1.1505\n",
            "Fold 3 val_acc = 0.5899\n",
            "Config {'k': (5, 5), 's': 2, 'p': (4, 4), 'ps': 3} â†’ mean_val_acc = 0.5924\n",
            "\n",
            "ğŸ† Best baseline: {'k': (3, 3), 's': 1, 'p': (4, 4), 'ps': 3}  (mean val acc â‰ˆ 0.6946)\n"
          ]
        }
      ],
      "source": [
        "kernel_sizes  = [(3,3), (5,5)]\n",
        "conv_strides  = [1, 2, 3]\n",
        "pool_sizes    = [(3,3), (4,4)]\n",
        "pool_strides  = [2, 3, 4]\n",
        "\n",
        "grid = []\n",
        "for k in kernel_sizes:\n",
        "    for s in conv_strides:\n",
        "        for p in pool_sizes:\n",
        "            for ps in pool_strides:\n",
        "                grid.append(dict(k=k, s=s, p=p, ps=ps))\n",
        "\n",
        "# random sample to shorten runtime\n",
        "N_SAMPLE = 12\n",
        "random.shuffle(grid); grid = grid[:N_SAMPLE]\n",
        "\n",
        "results = []\n",
        "for cfg in grid:\n",
        "    def build_baseline():\n",
        "        model = models.Sequential([\n",
        "            layers.Conv2D(32, cfg[\"k\"], strides=cfg[\"s\"], activation=\"relu\",\n",
        "                          padding=\"same\", input_shape=(32,32,3)),\n",
        "            layers.Conv2D(64, cfg[\"k\"], strides=cfg[\"s\"], activation=\"relu\",\n",
        "                          padding=\"same\"),\n",
        "            layers.MaxPooling2D(cfg[\"p\"], strides=cfg[\"ps\"]),\n",
        "            layers.Dropout(0.25),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(128, activation=\"relu\"),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(10, activation=\"softmax\")\n",
        "        ])\n",
        "        return model\n",
        "    mean_acc, _ = run_kfold(build_baseline, x_train_full, y_train_full,\n",
        "                            epochs=10, verbose=1)   # 10 epochs for speed\n",
        "    print(f\"Config {cfg} â†’ mean_val_acc = {mean_acc:.4f}\")\n",
        "    results.append((mean_acc, cfg))\n",
        "\n",
        "best_acc, best_cfg = max(results, key=lambda x: x[0])\n",
        "print(f\"\\nğŸ† Best baseline: {best_cfg}  (mean val acc â‰ˆ {best_acc:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VMOm01JCUAQ"
      },
      "source": [
        "\n",
        "-------------------------------------------------------------\n",
        " ## 4. Data augmentation with ImageDataGenerator\n",
        " Using the *best* hyper-parameters, we now train with random flips,\n",
        " width/height shifts, rotations, and zoom.  \n",
        " Data augmentation runs **in-memory** on the fly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLmMR_9BDE-R",
        "outputId": "0026986a-9369-4c5b-9b31-e8fe8c0b5b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Augmented Fold 1\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - accuracy: 0.2830 - loss: 1.9552 - val_accuracy: 0.5111 - val_loss: 1.3596\n",
            "Epoch 2/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.4496 - loss: 1.5128 - val_accuracy: 0.5747 - val_loss: 1.2029\n",
            "Epoch 3/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.5026 - loss: 1.3893 - val_accuracy: 0.5976 - val_loss: 1.1392\n",
            "Epoch 4/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.5221 - loss: 1.3453 - val_accuracy: 0.6323 - val_loss: 1.0535\n",
            "Epoch 5/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.5425 - loss: 1.2860 - val_accuracy: 0.6161 - val_loss: 1.0636\n",
            "Epoch 6/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.5517 - loss: 1.2543 - val_accuracy: 0.6201 - val_loss: 1.0704\n",
            "Epoch 7/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.5667 - loss: 1.2258 - val_accuracy: 0.6213 - val_loss: 1.0608\n",
            "Epoch 8/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 43ms/step - accuracy: 0.5762 - loss: 1.2025 - val_accuracy: 0.6463 - val_loss: 0.9949\n",
            "Epoch 9/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5702 - loss: 1.2004 - val_accuracy: 0.6429 - val_loss: 1.0048\n",
            "Epoch 10/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.5934 - loss: 1.1593 - val_accuracy: 0.6673 - val_loss: 0.9487\n",
            "Epoch 11/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.5913 - loss: 1.1665 - val_accuracy: 0.6708 - val_loss: 0.9303\n",
            "Epoch 12/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.5969 - loss: 1.1481 - val_accuracy: 0.6804 - val_loss: 0.9062\n",
            "Epoch 13/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.5930 - loss: 1.1338 - val_accuracy: 0.6716 - val_loss: 0.9387\n",
            "Epoch 14/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.6019 - loss: 1.1181 - val_accuracy: 0.6690 - val_loss: 0.9330\n",
            "Epoch 15/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 43ms/step - accuracy: 0.6066 - loss: 1.1167 - val_accuracy: 0.6808 - val_loss: 0.9191\n",
            "Epoch 16/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.6064 - loss: 1.1101 - val_accuracy: 0.6593 - val_loss: 0.9867\n",
            "Epoch 17/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6177 - loss: 1.0922 - val_accuracy: 0.6839 - val_loss: 0.9089\n",
            "Epoch 18/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.6179 - loss: 1.0910 - val_accuracy: 0.6764 - val_loss: 0.9344\n",
            "Epoch 19/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.6207 - loss: 1.0726 - val_accuracy: 0.6831 - val_loss: 0.9057\n",
            "Epoch 20/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6222 - loss: 1.0653 - val_accuracy: 0.6880 - val_loss: 0.8871\n",
            "\n",
            " Augmented Fold 2\n",
            "Epoch 1/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 46ms/step - accuracy: 0.2952 - loss: 1.9140 - val_accuracy: 0.5172 - val_loss: 1.3427\n",
            "Epoch 2/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.4608 - loss: 1.4945 - val_accuracy: 0.5507 - val_loss: 1.2603\n",
            "Epoch 3/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.5075 - loss: 1.3643 - val_accuracy: 0.5996 - val_loss: 1.1313\n",
            "Epoch 4/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.5336 - loss: 1.3034 - val_accuracy: 0.6180 - val_loss: 1.0857\n",
            "Epoch 5/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5495 - loss: 1.2645 - val_accuracy: 0.6114 - val_loss: 1.0810\n",
            "Epoch 6/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.5607 - loss: 1.2241 - val_accuracy: 0.6286 - val_loss: 1.0414\n",
            "Epoch 7/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.5804 - loss: 1.1876 - val_accuracy: 0.6222 - val_loss: 1.0786\n",
            "Epoch 8/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.5781 - loss: 1.1797 - val_accuracy: 0.6443 - val_loss: 1.0043\n",
            "Epoch 9/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5905 - loss: 1.1548 - val_accuracy: 0.6562 - val_loss: 0.9775\n",
            "Epoch 10/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.6050 - loss: 1.1380 - val_accuracy: 0.6416 - val_loss: 1.0173\n",
            "Epoch 11/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6071 - loss: 1.1239 - val_accuracy: 0.6685 - val_loss: 0.9509\n",
            "Epoch 12/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.6044 - loss: 1.1196 - val_accuracy: 0.6617 - val_loss: 0.9677\n",
            "Epoch 13/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.6113 - loss: 1.1029 - val_accuracy: 0.6686 - val_loss: 0.9631\n",
            "Epoch 14/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6211 - loss: 1.0898 - val_accuracy: 0.6470 - val_loss: 1.0082\n",
            "Epoch 15/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6207 - loss: 1.0746 - val_accuracy: 0.6873 - val_loss: 0.8874\n",
            "Epoch 16/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6261 - loss: 1.0668 - val_accuracy: 0.6848 - val_loss: 0.9022\n",
            "Epoch 17/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6324 - loss: 1.0494 - val_accuracy: 0.7008 - val_loss: 0.8571\n",
            "Epoch 18/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6314 - loss: 1.0543 - val_accuracy: 0.6866 - val_loss: 0.9007\n",
            "Epoch 19/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6330 - loss: 1.0497 - val_accuracy: 0.6701 - val_loss: 0.9534\n",
            "Epoch 20/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.6410 - loss: 1.0321 - val_accuracy: 0.6901 - val_loss: 0.9032\n",
            "\n",
            " Augmented Fold 3\n",
            "Epoch 1/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 46ms/step - accuracy: 0.2758 - loss: 1.9499 - val_accuracy: 0.4855 - val_loss: 1.4384\n",
            "Epoch 2/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.4530 - loss: 1.5246 - val_accuracy: 0.5509 - val_loss: 1.2341\n",
            "Epoch 3/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.4915 - loss: 1.4116 - val_accuracy: 0.5812 - val_loss: 1.1797\n",
            "Epoch 4/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5113 - loss: 1.3562 - val_accuracy: 0.6114 - val_loss: 1.0765\n",
            "Epoch 5/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.5294 - loss: 1.3176 - val_accuracy: 0.6285 - val_loss: 1.0558\n",
            "Epoch 6/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5413 - loss: 1.2840 - val_accuracy: 0.6304 - val_loss: 1.0367\n",
            "Epoch 7/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5587 - loss: 1.2482 - val_accuracy: 0.6339 - val_loss: 1.0255\n",
            "Epoch 8/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.5599 - loss: 1.2284 - val_accuracy: 0.6121 - val_loss: 1.1227\n",
            "Epoch 9/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5743 - loss: 1.2011 - val_accuracy: 0.6491 - val_loss: 0.9849\n",
            "Epoch 10/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - accuracy: 0.5772 - loss: 1.1917 - val_accuracy: 0.6506 - val_loss: 1.0163\n",
            "Epoch 11/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5825 - loss: 1.1871 - val_accuracy: 0.6520 - val_loss: 1.0018\n",
            "Epoch 12/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.5901 - loss: 1.1707 - val_accuracy: 0.6608 - val_loss: 0.9812\n",
            "Epoch 13/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.5911 - loss: 1.1591 - val_accuracy: 0.6565 - val_loss: 0.9806\n",
            "Epoch 14/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6031 - loss: 1.1265 - val_accuracy: 0.6674 - val_loss: 0.9506\n",
            "Epoch 15/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.6010 - loss: 1.1327 - val_accuracy: 0.6718 - val_loss: 0.9445\n",
            "Epoch 16/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.6038 - loss: 1.1316 - val_accuracy: 0.6716 - val_loss: 0.9457\n",
            "Epoch 17/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6092 - loss: 1.1210 - val_accuracy: 0.6830 - val_loss: 0.9124\n",
            "Epoch 18/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6103 - loss: 1.0995 - val_accuracy: 0.6768 - val_loss: 0.9420\n",
            "Epoch 19/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6108 - loss: 1.1034 - val_accuracy: 0.6870 - val_loss: 0.9118\n",
            "Epoch 20/20\n",
            "\u001b[1m521/521\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.6193 - loss: 1.0849 - val_accuracy: 0.6798 - val_loss: 0.9489\n",
            "\n",
            " Mean val acc with augmentation: 0.6860\n"
          ]
        }
      ],
      "source": [
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "def build_augmented():\n",
        "    return models.Sequential([\n",
        "        layers.Conv2D(32, best_cfg[\"k\"], strides=best_cfg[\"s\"],\n",
        "                      activation=\"relu\", padding=\"same\",\n",
        "                      input_shape=(32,32,3)),\n",
        "        layers.Conv2D(64, best_cfg[\"k\"], strides=best_cfg[\"s\"],\n",
        "                      activation=\"relu\", padding=\"same\"),\n",
        "        layers.MaxPooling2D(best_cfg[\"p\"], strides=best_cfg[\"ps\"]),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "def run_kfold_aug(build_fn, X, y, folds=3, epochs=20, batch_size=64):\n",
        "    kf = KFold(n_splits=folds, shuffle=True, random_state=SEED)\n",
        "    acc_per_fold = []\n",
        "    for fold, (tr, va) in enumerate(kf.split(X)):\n",
        "        print(f\"\\n Augmented Fold {fold+1}\")\n",
        "        model = build_fn()\n",
        "        model.compile(optimizer=\"adam\",\n",
        "                      loss=\"categorical_crossentropy\",\n",
        "                      metrics=[\"accuracy\"])\n",
        "        # flow on subset\n",
        "        train_gen = datagen.flow(X[tr], y[tr], batch_size=batch_size, seed=SEED)\n",
        "        val_data  = (X[va], y[va])\n",
        "        hist = model.fit(train_gen, epochs=20, verbose=1,\n",
        "                         validation_data=val_data)\n",
        "        acc = hist.history[\"val_accuracy\"][-1]\n",
        "        acc_per_fold.append(acc)\n",
        "        keras.backend.clear_session(); gc.collect()\n",
        "    return np.mean(acc_per_fold)\n",
        "\n",
        "aug_acc = run_kfold_aug(build_augmented, x_train_full, y_train_full)\n",
        "print(f\"\\n Mean val acc with augmentation: {aug_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lej__qA8DcjI"
      },
      "source": [
        "-------------------------------------------------------------\n",
        "## 5. Transfer learning â€“ VGG19 & EfficientNetB0\n",
        "We resize CIFAR-10 images to 224Ã—224 (VGG) or 224Ã—224 (EfficientNetB0\n",
        "default) and fine-tune *two* pre-trained models from Keras Applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQu6CIlo-VIQ",
        "outputId": "b84685af-2270-4ca1-a78d-5ed457fea339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Transfer learning: VGG19 ====\n",
            "\n",
            "â–¶ Fold 1/3\n",
            "Epoch 1/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 299ms/step - accuracy: 0.7389 - loss: 0.8179 - val_accuracy: 0.8410 - val_loss: 0.4682\n",
            "Epoch 2/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 295ms/step - accuracy: 0.8731 - loss: 0.3620 - val_accuracy: 0.8519 - val_loss: 0.4303\n",
            "Epoch 3/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 295ms/step - accuracy: 0.8950 - loss: 0.2990 - val_accuracy: 0.8657 - val_loss: 0.4041\n",
            "Epoch 4/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 295ms/step - accuracy: 0.9076 - loss: 0.2529 - val_accuracy: 0.8640 - val_loss: 0.4165\n",
            "Epoch 5/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 335ms/step - accuracy: 0.9242 - loss: 0.2131 - val_accuracy: 0.8505 - val_loss: 0.4784\n",
            "  â†’ Best val_accuracy: 0.8657\n",
            "\n",
            "â–¶ Fold 2/3\n",
            "Epoch 1/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 297ms/step - accuracy: 0.7518 - loss: 0.7728 - val_accuracy: 0.8497 - val_loss: 0.4415\n",
            "Epoch 2/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 295ms/step - accuracy: 0.8718 - loss: 0.3780 - val_accuracy: 0.8631 - val_loss: 0.4043\n",
            "Epoch 3/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 335ms/step - accuracy: 0.8930 - loss: 0.3073 - val_accuracy: 0.8600 - val_loss: 0.4172\n",
            "Epoch 4/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 295ms/step - accuracy: 0.9113 - loss: 0.2505 - val_accuracy: 0.8703 - val_loss: 0.3996\n",
            "Epoch 5/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 295ms/step - accuracy: 0.9276 - loss: 0.2073 - val_accuracy: 0.8623 - val_loss: 0.4418\n",
            "  â†’ Best val_accuracy: 0.8703\n",
            "\n",
            "â–¶ Fold 3/3\n",
            "Epoch 1/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 336ms/step - accuracy: 0.7463 - loss: 0.8016 - val_accuracy: 0.8498 - val_loss: 0.4485\n",
            "Epoch 2/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 295ms/step - accuracy: 0.8751 - loss: 0.3644 - val_accuracy: 0.8628 - val_loss: 0.4004\n",
            "Epoch 3/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 335ms/step - accuracy: 0.8959 - loss: 0.2987 - val_accuracy: 0.8585 - val_loss: 0.4309\n",
            "Epoch 4/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 295ms/step - accuracy: 0.9054 - loss: 0.2653 - val_accuracy: 0.8637 - val_loss: 0.4338\n",
            "Epoch 5/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 335ms/step - accuracy: 0.9252 - loss: 0.2108 - val_accuracy: 0.8691 - val_loss: 0.4165\n",
            "  â†’ Best val_accuracy: 0.8691\n",
            "\n",
            "ğŸ† VGG19 mean val_accuracy over 3 folds: 0.8683\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_pre\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np, gc\n",
        "\n",
        "# 1) Hyperparameters\n",
        "IMG_SIZE   = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS     = 5\n",
        "FOLDS      = 3\n",
        "SEED       = 2025\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# 2) Dataset factory: resize â†’ preprocess_input â†’ batch\n",
        "def make_vgg_dataset(X, y, training=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if training:\n",
        "        ds = ds.shuffle(buffer_size=len(X), seed=SEED)\n",
        "    # Resize each image to (224,224)\n",
        "    ds = ds.map(\n",
        "        lambda img, lbl: (tf.image.resize(img, (IMG_SIZE, IMG_SIZE)), lbl),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    # Apply VGG19 preprocess_input (zero-centers on ImageNet means)\n",
        "    ds = ds.map(\n",
        "        lambda img, lbl: (vgg_pre(img * 255.0), lbl),  # scale back to [0â€“255]\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# 3) Build & compile a fresh VGG19-based model\n",
        "def build_vgg_model():\n",
        "    base = VGG19(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    )\n",
        "    base.trainable = False\n",
        "\n",
        "    inp = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    x   = base(inp, training=False)\n",
        "    x   = layers.GlobalAveragePooling2D()(x)\n",
        "    x   = layers.Dense(256, activation=\"relu\")(x)\n",
        "    out = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "    m = models.Model(inp, out)\n",
        "    m.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# 4) 3-fold CV runner for VGG19\n",
        "def run_kfold_vgg(X, y):\n",
        "    skf    = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "    labels = np.argmax(y, axis=1)\n",
        "    accs   = []\n",
        "\n",
        "    for fold, (tr, va) in enumerate(skf.split(X, labels), start=1):\n",
        "        print(f\"\\nâ–¶ Fold {fold}/{FOLDS}\")\n",
        "        model = build_vgg_model()\n",
        "\n",
        "        train_ds = make_vgg_dataset(X[tr], y[tr], training=True)\n",
        "        val_ds   = make_vgg_dataset(X[va], y[va], training=False)\n",
        "\n",
        "        hist = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=EPOCHS,\n",
        "            verbose=1\n",
        "        )\n",
        "        best_val = max(hist.history[\"val_accuracy\"])\n",
        "        print(f\"  â†’ Best val_accuracy: {best_val:.4f}\")\n",
        "        accs.append(best_val)\n",
        "\n",
        "        keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "    mean_acc = float(np.mean(accs))\n",
        "    print(f\"\\nğŸ† VGG19 mean val_accuracy over {FOLDS} folds: {mean_acc:.4f}\")\n",
        "    return mean_acc\n",
        "\n",
        "# 5) Execute VGG19 transfer learning\n",
        "print(\"\\n==== Transfer learning: VGG19 ====\")\n",
        "acc_vgg = run_kfold_vgg(x_train_full, y_train_full)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRPZltDliJ6A"
      },
      "source": [
        "# efficient net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC2xVYoEhxXA",
        "outputId": "76d52c98-91b0-452b-c702-8b522a96924a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Transfer learning: EfficientNetB0 ====\n",
            "\n",
            "â–¶ Fold 1/3\n",
            "Epoch 1/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 91ms/step - accuracy: 0.8164 - loss: 0.5334 - val_accuracy: 0.8931 - val_loss: 0.3088\n",
            "Epoch 2/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 57ms/step - accuracy: 0.9006 - loss: 0.2838 - val_accuracy: 0.8985 - val_loss: 0.2951\n",
            "Epoch 3/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 57ms/step - accuracy: 0.9191 - loss: 0.2281 - val_accuracy: 0.8953 - val_loss: 0.3085\n",
            "Epoch 4/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 54ms/step - accuracy: 0.9300 - loss: 0.1992 - val_accuracy: 0.9044 - val_loss: 0.2931\n",
            "Epoch 5/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 57ms/step - accuracy: 0.9442 - loss: 0.1630 - val_accuracy: 0.9048 - val_loss: 0.3010\n",
            "  â†’ Best val_accuracy: 0.9048\n",
            "\n",
            "â–¶ Fold 2/3\n",
            "Epoch 1/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 91ms/step - accuracy: 0.8273 - loss: 0.5246 - val_accuracy: 0.8976 - val_loss: 0.2958\n",
            "Epoch 2/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 57ms/step - accuracy: 0.9006 - loss: 0.2864 - val_accuracy: 0.9074 - val_loss: 0.2645\n",
            "Epoch 3/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 57ms/step - accuracy: 0.9181 - loss: 0.2354 - val_accuracy: 0.9022 - val_loss: 0.2869\n",
            "Epoch 4/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 58ms/step - accuracy: 0.9331 - loss: 0.1889 - val_accuracy: 0.9068 - val_loss: 0.2749\n",
            "Epoch 5/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 58ms/step - accuracy: 0.9425 - loss: 0.1626 - val_accuracy: 0.9117 - val_loss: 0.2673\n",
            "  â†’ Best val_accuracy: 0.9117\n",
            "\n",
            "â–¶ Fold 3/3\n",
            "Epoch 1/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 76ms/step - accuracy: 0.8251 - loss: 0.5215 - val_accuracy: 0.8988 - val_loss: 0.3010\n",
            "Epoch 2/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 57ms/step - accuracy: 0.9065 - loss: 0.2714 - val_accuracy: 0.8984 - val_loss: 0.2982\n",
            "Epoch 3/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 57ms/step - accuracy: 0.9233 - loss: 0.2218 - val_accuracy: 0.9043 - val_loss: 0.2956\n",
            "Epoch 4/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 57ms/step - accuracy: 0.9354 - loss: 0.1859 - val_accuracy: 0.9042 - val_loss: 0.2966\n",
            "Epoch 5/5\n",
            "\u001b[1m1042/1042\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - accuracy: 0.9427 - loss: 0.1603 - val_accuracy: 0.9083 - val_loss: 0.2883\n",
            "  â†’ Best val_accuracy: 0.9083\n",
            "\n",
            "ğŸ† EfficientNetB0 mean val_accuracy over 3 folds: 0.9083\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_pre\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np, gc\n",
        "\n",
        "# 1) Hyperparameters\n",
        "IMG_SIZE   = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS     = 5\n",
        "FOLDS      = 3\n",
        "SEED       = 2025\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# 2) Dataset factory: resize â†’ scale â†’ preprocess â†’ batch\n",
        "def make_eff_dataset(X, y, training=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if training:\n",
        "        ds = ds.shuffle(len(X), seed=SEED)\n",
        "    # Resize each image to (224,224), then scale up to [0â€“255]\n",
        "    ds = ds.map(\n",
        "        lambda img, lbl: (tf.image.resize(img, (IMG_SIZE, IMG_SIZE)) * 255.0, lbl),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    # Apply EfficientNet preprocess_input (maps [0â€“255]â†’[-1,1])\n",
        "    ds = ds.map(\n",
        "        lambda img, lbl: (eff_pre(img), lbl),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# 3) Model builder\n",
        "def build_effnet_model():\n",
        "    base = EfficientNetB0(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "    )\n",
        "    base.trainable = False\n",
        "\n",
        "    inp = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    x   = base(inp, training=False)\n",
        "    x   = layers.GlobalAveragePooling2D()(x)\n",
        "    x   = layers.Dense(256, activation=\"relu\")(x)\n",
        "    out = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "    m = models.Model(inp, out)\n",
        "    m.compile(optimizer=\"adam\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "    return m\n",
        "\n",
        "# 4) 3-fold CV runner\n",
        "def run_kfold_effnet(X, y):\n",
        "    skf    = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "    labels = np.argmax(y, axis=1)\n",
        "    accs   = []\n",
        "\n",
        "    for fold, (tr, va) in enumerate(skf.split(X, labels), start=1):\n",
        "        print(f\"\\nâ–¶ Fold {fold}/{FOLDS}\")\n",
        "        model = build_effnet_model()\n",
        "\n",
        "        train_ds = make_eff_dataset(X[tr], y[tr], training=True)\n",
        "        val_ds   = make_eff_dataset(X[va], y[va], training=False)\n",
        "\n",
        "        hist = model.fit(\n",
        "            train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=EPOCHS,\n",
        "            verbose=1\n",
        "        )\n",
        "        best_val = max(hist.history[\"val_accuracy\"])\n",
        "        print(f\"  â†’ Best val_accuracy: {best_val:.4f}\")\n",
        "        accs.append(best_val)\n",
        "\n",
        "        keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "    mean_acc = float(np.mean(accs))\n",
        "    print(f\"\\nğŸ† EfficientNetB0 mean val_accuracy over {FOLDS} folds: {mean_acc:.4f}\")\n",
        "    return mean_acc\n",
        "\n",
        "# 5) Execute\n",
        "print(\"\\n==== Transfer learning: EfficientNetB0 ====\")\n",
        "acc_eff = run_kfold_effnet(x_train_full, y_train_full)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5gP9vqkrTUp"
      },
      "source": [
        "So we see the accuracy extremly increased when using pretrained models for transfer learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6tEWEl6F5Ir"
      },
      "source": [
        "\n",
        "# **Optional fine-tuning stage:**  \n",
        "We can unfreeze the top N layers of the best backbone and train a few more\n",
        "epochs with a low learning-rate not done in this notebook , just an idea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX5BqZuVGWEj"
      },
      "outputs": [],
      "source": [
        "# with below code we can achieve the mentioned task but its optional\n",
        "# for layer in efficient.layers[-20:]:\n",
        "#     layer.trainable = True\n",
        "# efficient_acc_ft, _ = run_kfold(lambda: build_transfer(efficient),\n",
        "#                                 x_train_big, y_train_full,\n",
        "#                                 epochs=3, batch_size=32, verbose=1)\n",
        "# print(f\"EfficientNet fine-tuned acc = {efficient_acc_ft:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbkdZZxiGtBZ"
      },
      "source": [
        "## 6. Final evaluation on held-out test set\n",
        "We retrain the *best* overall model (here we pick EfficientNet for\n",
        "illustration) on the full training data and report accuracy on the\n",
        "original 10 000-image CIFAR-10 test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "UYtx2c2NGwEn",
        "outputId": "885cc335-c1f7-436c-baa2-0e74fdb2e261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¯ Test accuracy = 0.8892\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_pre\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np, gc\n",
        "# â”€â”€â”€ Ensure resizing happens on the CPU (avoids GPU OOM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "with tf.device('/CPU:0'):\n",
        "    x_train_big = tf.image.resize(x_train_full, (IMG_SIZE, IMG_SIZE)).numpy()\n",
        "    x_test_big  = tf.image.resize(x_test,      (IMG_SIZE, IMG_SIZE)).numpy()\n",
        "\n",
        "# â”€â”€â”€ Final evaluation with the best backbone â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "best_backbone = efficient   # your chosen backbone\n",
        "best_backbone.trainable = False\n",
        "\n",
        "model_final = build_transfer(best_backbone)\n",
        "model_final.fit(\n",
        "    x_train_big, y_train_full,\n",
        "    epochs=5, batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model_final.evaluate(x_test_big, y_test, verbose=0)\n",
        "print(f\"\\nğŸ¯ Test accuracy = {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HURHyvkeWmTF"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 7. Discussion â€“ receptive field (window size)\n",
        "Increasing the convolutional **kernel size** expands the receptive\n",
        "field, enabling neurons to integrate wider spatial context in a single\n",
        "layer. On CIFAR-10 we observed that:\n",
        "\n",
        "* Going from 3Ã—3 to 5Ã—5 kernels modestly **improved accuracy** because\n",
        "  objects often occupy a sizeable fraction of 32Ã—32 images, so a wider\n",
        "  field captures discriminative colour/texture cues in fewer layers.\n",
        "* Jumping to 7Ã—7 hurt performance unless stride/pooling were adjusted,\n",
        "  because the large window **reduces feature-map resolution early**,\n",
        "  making localisation of fine details (e.g. cat whiskers) harder.\n",
        "* Very small kernels (1Ã—1) are useful for channel mixing but alone\n",
        "  lack spatial context; very large kernels behave like dense layers\n",
        "  with many parameters, risking over-fitting and slower training.\n",
        "\n",
        "**Why?** Receptive-field size controls the bias-variance trade-off:\n",
        "- **Larger windows** â†’ fewer steps to cover the input, capturing\n",
        "  global shapes but sacrificing precise localisation.  \n",
        "- **Smaller windows** â†’ deeper hierarchies that slowly aggregate local\n",
        "  features into global ones, often yielding better generalisation on\n",
        "  natural images (the success of VGG/ResNet stems from stacks of 3Ã—3\n",
        "  kernels).\n",
        "\n",
        "AS mentioned in the above the best resluts were for the Best baseline: {'k': (3, 3), 's': 1, 'p': (4, 4), 'ps': 3}  (mean val acc â‰ˆ 0.6946)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
